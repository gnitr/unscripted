
Test 9 dec 2017, asus, cp36, simulate 100, rps:

306: aiohttp, synced
377: aiohttp, asynced

370: urllib3, async
398: urllib3, sync

470: Pycurl, synced
490: Pycurl, async

607: websockets, synced
170: websockets, async
*516-769: websockets, async, 1 session per bot
1000: with buffered stdout
65: same on pi3
110: remote, websocket, async (server/pi3 93%, asus 32%)

python -m cProfile -o s.cperf manage.py ucore runserver 0:8000 & sleep 2; python -m cProfile -o c.cperf manage.py utest any simulate --cycles 2000 --stop

python -m cProfile -o s.cperf manage.py ucore runserver 0:8001 & sleep 2; python -m cProfile -o c.cperf manage.py utest any simulate --cycles 500 --stop

python -m cProfile -o pa.cperf manage.py utest any pactions --cycles 1000

Why pi3 so slow: 100rps vs 1000rps on asus 
    => pi3 ~10 x slower
14s: pactions 2000 on pi3
1.6: pactions 2000 on asus 
    => pi3 ~10 x slower
    => speed limit for pure logic (excluding the communication) is 1250 walking steps /s ???
2703: conns (asus, aiohttp>websockets)
250: pi3
    => pi3 connections are also 10 x slower 
    
Optimise cursor (replace with tuple)
4.449s: pactions 20000
2.422s: pactions 20000

=> multithreading ?

1. python 3 runserver doesn't save pymemdb collection when ctrl-c is pressed
    pm runserver 0:8000 --nothreading --noreload
2. seg fault with pypy server when running a simulation
    caused by ujson (works well when use json instead)
3. pi3 64 bits is much slower than 32bits, why?

pm ucore uncache && pm ucore crunch && pm ucore new && pm utest any repop_well
gunicorn -w 1 unscripted.wsgi:application

Optimisation:
    Observations:
        pactions is much slower when look at the iterations on screen, why?

        (sudo apt-get install libpcre3 libpcre3-dev # may be needed for uwsgi)
        (sudo apt-get install pypy-libs # may be needed for uwsgi)
        # uwsgi --i uwsgi.ini
        (sudo apt-get install libev-dev)
        python bjrn.py
        time pm utest any conn --cycles 10000
        # 0.5M / s: loop with just print
        # 3M / s  : > /dev/null 
        # 20M / s : without print 
        #
        # 410 / s : empty requests + print (runserver)
        # 483 / s : empty requests (runserver)
        # 550 / s : empty requests (uwsgi) (60% in client-side) => runserver speed varies a lot (300 to 900)
        # 1550 / s: request with PyCurl (80% in server-side) => triples the speed of the client
        # 1700-2000 / s: empty requests (bjoern + PyCurl, asus (bjoern 3x faster than runserver), 80% server-side)
        # 2250    : (bjoern + ujson on server-side; XPS)
        # 1500-2500: (uwsgi (pypy) + ujson on server-side; XPS)
        # 2400-2750: same with cpu-affinity, master, single-interpreter
        # 2800    : gunicorn & pypy (BUT no keep-alive)
        
        => uwsgi (unopt) not much faster than runserver
        !!!! runserver returns http/1.0, i.e. no keep-alive
        => PyCurl vs requests => 3x
        => Bjoern vs uWsgi => 3x
        Note: they don't multiply together, it's more like this: new_speed = min(3 x old_server_speed, 3 x old_client_speed)
        
        # 1000 * 10 simulation reqs / 47s => 212 / s
        
        # Targets (assuming 70 years, and one day):
        #   10 cycles / s   => 7 years, 2.5 hours  (100 rq/s)
        # = 100             => 9 months, 15 mins   (1000 rq/s)
        # + 1000            => 1 months, 1.5 mins
        #   10000           => 8 hours
        
        # 650 rps asus c36 websockets (local simulation)
        # 514 c36<-pypy3
        # 258 rps pypy3
        # 281 pypy3<-c36
        => pypy on server side is much slower
        Ceilings:
        pactions 2631 rps (c36)
        conn 2450 rps (c36)
        What's missing is the encode/decode + list of bots
        if we assume conn & pactions are cumulative => 1/(1/2631 + 1/2450) = 1268 rps
        => around half the time is unaccounted for in simulate, what is it?
        => then we can increase it by using green threads
        # sim c35 from pi3 to asus: 53rps
        # sim c35 pi3 internally: 83 rps
        # conn c35 pi3 210 rps
        => optimise pi3
        => asyncio
        
        TODO:
        * - replace django with something else: 
            * nothing!
            - sanic
            - falcon
            - bottle
            - flask: single threaded
        * - websockets
        - cpu affinity
            * improves cpython 'conn': 1686, 1747, 1520 from 1459, 1450
        - uwsgi queue
            - https://stackoverflow.com/a/36452474/3748764
            X change uwsgi:listen option won't make a difference b/c client wait for response before sending next request...
            It is like a single thread split between two processes! 
        - replace bjoern/uwsgi/runserver with something fats and pypy compatible:
            - uwsgi: 
            * gunicorn: ~2800 (pypy) req /s but it requires nginx to deal with http/1.1, keep-alive and buffering requests
            X cherrypy: ~5000 req /s but hangs on simulate
            ~ bjoern: not pypy-compatible
            X mainheld (very poor doc; obscure fail on second request when keep-alive = 100)
                http://nullege.com/codes/show/src%40g%40o%40go-rest-api-server-HEAD%40python%40rest_server.py/47/meinheld.server.set_keepalive/python
        () DEBUG = False (Doesn't seem to make much diff on simulate)
        - TEST if keep-alive actually works
            - Check with curl: https://serverfault.com/a/554668
            - curl -Iv http://127.0.0.1:8000/api/1/ --next http://127.0.0.1:8000/api/1/ 2>&1
            => NOT with runserver; OK with uwsgi; OK with bjoern
        - use pypy
         DONE try json alternatives:
            - ujson (CPython only): OK, but for simple message, not a big difference (<10%) 
            - msgpack
            - pypy
        - Make sure we don't have 301 Move due to trailing /

    From top (algo/caching/avoidance) / from bottom (alternatives)
    
    django channels?
    
    80% of the time is spent on the server side (look at top during execution)
    socket
        better library?

    mongdb tuning?
    
    Single-thread?!
        we queue all requests on server side.
        - we can't parallelise the requests
        + dramatically simplifies the database: all objects are pythons and stay in memory
        + no need to worry about sharing, locking, race conditions, ...
        + no latency due to with python - db communications
        0 we must manage persistance
        - only feasible for small worlds
        - every Write HAS to go via the same instance
        - lacks all the nice database stuff like advanced queries, GUIs, libs...
            => can persists as MongoDB
    
    * multiprocess / multithread?
        runserver already has 4 workers!
        nginx?
    
    algo
        is_position_valid
        obstructing
    
    * in memory db:
        mongodb ramdisk 
        python objects shared in memory
            how do we keep them thread-safe?
        
    

python -m cProfile -o s2.cperf manage.py utest any pactions --cycles 10000
pyprof2calltree -k -i s2.cperf

mind:
    implement basic NN for action selection
    with random units functions
visible:
    angle and distances to other things rather than positions
    hide creation date? show number of actions instead
perf:
    cache mongo
    separate client and server to different machines
test world:
    smaller
    die sooner?
collision bots/things:


! see in a range
! act in a narrower range

Phase 1

[DONE] Django project and apps skeletons
[DONE] Rewrite models with MongoDB bue to Thing inheritence and flexible schema
[DONE] Dummy models for
    . Thing
    . World
    . Bot
. Web api framework:
    [DONE] create a world        POST /worlds
    [DONE] list words            GET /worlds
    [DONE] remove a world        DEL /worlds/X
    [DONE] create a bot          POST /worlds/X/bots
    [DONE] things in a world     GET /worlds/X/things
    [DONE] move bot              POST /things/Y/actions/walk/X?angle=0.3
    [DONE] change parentid to objectid
    [DONE] use y has real height from ground 
. Crude visualisation
    [DONE] web page
    [DONE] get world data with web api
    . improve the low perf, 50% cpu on i7 for an empty map is prohibitive
    [DONE] very basic visualisation of bots on world map
    . camera:
        () add ability to move the camera (not just rotate and zoom)
        () rotate camera around itself
        [DONE] prevent camera to show reverse of ground
        . remember the last camera settings
        . follow bot mode
    [DONE] click on a bot
    . better colors for ground
    [DONE] better colors for bots
    [DONE] update the positions
() Command line tool that reflects Web API
    . ucore
    . create-POST, read-GET, update-PUT, rm-DELETE
[DONE] System for consistent IDs across the different layers:
    . Mongo doc._id (ObjectId) <-> Thing.pk (str) <-> api item.id (str)
. basic world engine
    [DONE] forward actions to targets
    . implement walk
    . make sure position is valid (not outside world boundary or colliding with something else)
. remote bot
    [DONE] simple command to execute action every x seconds
    [DONE] random walk
    . 
. release online
    . pb with domain config on web hosting side, site still links to godaddy
    

Thing
    pos
    dims
    type
    parent
    properties
        _private
        public
    
class Thing
    actionX
    _actionY
    
    